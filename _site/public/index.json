[{"authors":null,"categories":null,"content":"","date":1637539200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1637539200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Guande Wu (吴冠德)","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8783e68ef1ab9e7bbbdd3611151e06ca","permalink":"https://www.gdwu.xyz/backup/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/backup/posts/","section":"backup","summary":"","tags":null,"title":"Recent News","type":"backup"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchmey\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://www.gdwu.xyz/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Guande Wu (吴冠德)","Jianzhe Lin","Claudio T. Silva"],"categories":null,"content":"","date":1637539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637539200,"objectID":"ee3bb665904cc411fecc04e2071a9b46","permalink":"https://www.gdwu.xyz/publication/era/","publishdate":"2021-10-15T00:00:00Z","relpermalink":"/publication/era/","section":"publication","summary":"Video summarization aims to simplify large scale video browsing by generating concise, short summaries that diver from but well represent the original video...","tags":["Video Summarization"],"title":"ERA: Entity–relationship Aware Video Summarization with Wasserstein GAN","type":"publication"},{"authors":["Guande Wu (吴冠德)","Jianzhe Lin","Claudio T. Silva"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"5167c24219fbf25fb2446f360d6a204d","permalink":"https://www.gdwu.xyz/publication/intent-vizor/","publishdate":"2022-03-02T00:00:00Z","relpermalink":"/publication/intent-vizor/","section":"publication","summary":"The target of automatic Video summarization is to create a short skim of the original long video while preserving the major content/events...","tags":["Video Summarization"],"title":"IntentVizor: Towards Generic Query Guided Interactive Video Summarization","type":"publication"},{"authors":["Guande Wu (吴冠德)"],"categories":["Demo","教程"],"content":"Summary System Inputs Outputs Method data publication Reverse-Engineering Visualizations chart bitmap image visual encoding speciﬁcation using inferred text elements a combination of automatically generated charts and manually annotated charts from 3rd party sources EuroVIS 2017 Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations chart bitmap image color encodings Color Legend Identiﬁcation-\u0026gt;Color Legend Classiﬁcation by CNN -\u0026gt; Color Extraction by algorithms -\u0026gt; Legend Text Extraction -\u0026gt; Associating the text values with the color information Visualization images from both academic papers and the web sites of scientiﬁc institutions TVCG 2017 Deconstructing and restyling D3 visualizations D3.js visualization data, marks and mappings between them Algorithms d3.js visualizations from web UIST’14 A system for understanding imaged infographics and its applications Imaged infographics located in document pages graphical symbols OCR and other algorithms basically rule-based pdfs DocEng 07 ReVision chart images chart type, graphical marks and data infer the chart types by SVM and use the specific types to extract data and graphical marks A new corpus containing 2,601 chart images labeled with 10 categories using a semi-automated tool for querying Google image search. UIST’11 Scalable algorithms for scholarly figure mining and semantics pdf files figure metadata; does a figure contain sub-figures; classification, text summarization(only contains trends description) classifying the compound visualizations by the features proposed by Pelka. Classifying the figure types by SVM and Random Forest 6.7 million PDF ﬁles in CiteSeerX repository SBD’16 ChartSense bitmap images chart types and data a semi-automatic approach, classifying types by GoogLeNet Collecting 5659 images from google and labeling them manually CHI 2017 iVoLVER bitmap images new visualizations, data, chart types relying on manual annotation to extract data and encodings. No CHI 2016 Scatteract: Automated extraction of data from scatter plots scatter plot images data detecting ticks; OCR to extract value; find the closest value of a point generated scatter plots ECML PKDD 2017 Data Extraction from Charts via Single Deep Neural Network bar and pie charts(the authors mentioned that the model could extended to other types by augmenting data and revising the model) data a framework of a single deep neural network, which consists of object detection, text recognition and object matching modules. Simulated charts based on Microsoft Excel and the Matplotlib library arXiv.2019.06 Multimodal Deep Learning using Images and Text for Information Graphic Classification Images and text six categories of the data pattern and trends. joined embeddings of image and text VizML and other online images. human labeling after collecting ASSETS’18 Extracting Visual Encodings from Map Chart Images with Color-encoded Scalar Values bitmap images of map visual encodings and data OCR -\u0026gt; Value Inference -\u0026gt; Projection Inference map images from scientific documents, SIBGRAPI 2018 Interpreting Graphical Elements in Visualizations Deconstructing and restyling D3 visualizations\nIn this paper, Harper and Agrawala proposed a system for deconstructing D3.js visualizations that extracts data, marks and mappings between them. The technique exploits the fact that one can access both SVG elements and data directly in the web browser. The technique is limited in SVG-based visualizations which is only a small part of visualizations.\nA system for understanding imaged infographics and its applications.\nThis paper describes technical details and practical applications of the system they built for recognizing and understanding imaged infographics located in document pages. This technique perform vectorization on images and convert them into a set of lines, arcs in the vector form before graphical symbols are constructed. Then, it applied domain knowledge to to identify graphical symbols representing data for each chart type.\nReVision: Automated Classification, Analysis and Redesign of Chart Images\nReVision applies computer vision and machine learning techniques to identify the chart type. It then extracts the graphical marks and infers the underlying data. Using a corpus of images drawn from the web, ReVision achieves an image classiﬁcation accuracy of 96% across ten chart categories. They labeled the data manually.\nInterpreting Text in Visualizations Reverse-Engineering Visualizations: Recovering Visual Encodings from Chart Images\nThis paper proposed a text analysis pipeline that identifies text elements in a chart image, determines their bounding boxes, recognizes the text content using OCR, and classifies their role in the chart (e.g., chart title, x-axis label, y-axis title, etc.). They also also train a Convolutional Neural Network that classifies the type of graphical mark used to encode data in a chart (e.g., bars, lines, points, or areas). Together, They leverage the inferred text and chart type information to recover a visual encoding specification in a declarative grammar similar to Vega-Lite [SMWH17] or Tableau’s VizQL [STH02]. This chart specification can then be used for indexing, search, or retargeting of the input visualization.\nExtracting Data From Visualizations Scalable algorithms for scholarly figure mining and semantics\nThe paper reported scalable algorithms for generating semantic metadata for figures. The system has four sequential modules:\nExtraction of figure, caption and mention; Binary classification of figures as compound (contains sub-figures) or not; Three class classification of non compound figures as line graph, bar graph or others; Automatic processing of line graphs to generate a textual summary; They inferred the textual summery simply based on the data trends.\nCurve Separation for Line Graphs in Scholarly Documents\nLine graphs are abundant in scholarly papers. They are usually generated from a data table and that data can not be accessed. One important step in an automated data extraction pipeline is the curve separation problem: segmenting the pixels into separate curves. Previous work in this domain has focused on raster graphics extracted from scholarly PDFs, whereas most scholarly plots are embedded as vector graphics. They reported a system to extract these plots as SVG images and show how that can improve both the accuracy (90%) and the scalability (5-8 seconds) of the curve separation problem.\nChartSense: Interactive Data Extraction from Chart Images\nChartSense uses a semi-automatic approach to extract data from line, pie and bar charts. The authors compared ChartSense with ReVision and found that ChartSense was more accurate than ReVision.\niVoLVER: Interactive visual language for visualization extraction and reconstruction\nEnabling flexible acquisition of many types of data (text, colors, shapes, quantities, dates) from multiple source types (bitmap charts, webpages, photographs, SVGs, CSV files), iVoLVER allows users to create visualizations without textual programming. In doing so,the authors used existing work that uses computer vision approaches to extract data from existing graphics.\nData Extraction from Charts via Single Deep Neural Network\nThe model performs successfully on 79.4% of test simulated bar charts and 88.0% of test simulated pie charts, while for charts outside of the training domain it degrades for 57.5% and 62.3%, respectively.\n*ReVision: Automated Classiﬁcation, Analysis and Redesign of Chart Images *\nThe authors presented ReVision, a system that automatically redesigns visualizations to improve graphical perception. Given a bitmap image of a chart as input, ReVision applies computer vision and machine learning techniques to identify the chart type. It then extracts the graphical marks and infers the underlying data.\nRestyling Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations\nVisualizations “in the wild” often violate perceptual color design principles and may only be available as bitmap images. To address the problem, the authors contribute a method to semi-automatically extract color encodings from a bitmap visualization image.\nText and Visualization Multimodal Deep Learning using Images and Text for Information Graphic Classification\nIf a graphic is not described, explained in the text, or missing alt tags and other metadata (as is often the case in popular media), the intended message is lost or not adequately conveyed. In this work, the authors describe a multimodal deep learning approach that supports the communication of the intended message.\nOthers Beagle: Automated Extraction and Interpretation of Visualizations from the Web\nThe authors collected and extracted more than 41K SVG-based visualizations from the web. Rather than training a machine learning model or any thing, they use the data to study visualization usages. They found that most visualizations fall under four types: bar charts, line charts, scatter charts, and geographic maps. Though controversial, pie charts are relatively rare in practice. Our findings also indicate that users may prefer tools that emphasize a succinct set of visualization types, and provide diverse expert visualization examples.\nEvaluating ‘Graphical Perception’ with CNNs\nHow do CNNs perform when applied to graphical perception tasks?\nThe authors investigated this question by reproducing Cleveland and McGill’s seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. They measured the graphical perceptual capabilities of four network architectures on five different visualization tasks and compared to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, they find that CNNs are not currently a good model for human graphical perception.\nThey also visualize the activation map of CNN and try to understand the recognition process of visualizations.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://www.gdwu.xyz/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"A list of papers related to computational visualization interpretation and understanding.","tags":["Academic","开源"],"title":"Computational Visualization Interpretation","type":"post"},{"authors":["Guande Wu (吴冠德)"],"categories":["Demo","教程"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"fe627c7068de66375b0c6188977e5473","permalink":"https://www.gdwu.xyz/post/computational-understanding-visualization/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/computational-understanding-visualization/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://www.gdwu.xyz/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"29ba725bea45b97f286880bee9a95528","permalink":"https://www.gdwu.xyz/backup/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/backup/external-project/","section":"backup","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"backup"},{"authors":null,"categories":null,"content":"Overview Mobile sensing has offered efficient, cost-effective data collection procedures that opened new research frontiers, specifically in urban sensing and transportation. In the past, due to highly costly and time-consuming data collection procedures, a limited number of urban indicators were measured and made available to researchers. Hence, our understanding of cities on many frontiers was bounded by the ability to collect, record, manage, and store data. Recent advancements in producing low-cost sensing devices, together with the advent of new techniques in computer vision and machine learning, lead to the creation of massive data sets collected by fleets of sensor-equipped vehicles moving through streets.\nObjectives In this project, we propose to employ machine learning techniques for creating adaptive sampling profiles and a data-driven, opportunistic approach to data acquisition from moving sensors. Our immediate goal is to drastically cut down the cost of deploying video and image sensors, making them more practical. To this end, we plan to explore a novel research direction: detecting the salient frames in video data captured by sensors using computer vision, video segmentation algorithms. Then, a data-driven approach using ML will be employed to find the control features that enhance sensor data acquisition and prevent huge waste to the memory and storage resources. We plan to evaluate our proposed methods by demonstrating their effectiveness in a pedestrian mobility analysis. We provide a method to count pedestrians from a moving car instead of relying on the conventional methods of using fixed sensors or human counters, which due to their high cost, suffer from very limited spatial coverage.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8668f3d9a1ef52ca72f2134e2fd1c52c","permalink":"https://www.gdwu.xyz/project/c2smart-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/c2smart-project/","section":"project","summary":"This is part of the C2SMART (Connected Cities With Smart Transportation at NYU) Project \"Exploring AI-based Video Segmentation and Saliency Computation to Optimize Imagery-acquisition From Moving Vehicles\".","tags":["Deep Learning"],"title":"Video Summarization and Visual Analysis on Videos","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://www.gdwu.xyz/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]